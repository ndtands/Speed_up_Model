INFO 2022-06-06 15:39:13,013 [4142902042.py:<cell line: 8>:21]
Time for inference: 0.012606620788574219

INFO 2022-06-06 15:42:14,594 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.24636840820312, %, index: 151

INFO 2022-06-06 15:42:14,597 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.077691078186035, %, index: 237

INFO 2022-06-06 15:42:14,599 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573545932769775, %, index: 171

INFO 2022-06-06 15:42:14,600 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0198899507522583, %, index: 158

INFO 2022-06-06 15:42:14,601 [inference.py:<module>:29]
Time for inference: 0.0424041748046875

INFO 2022-06-06 15:42:45,967 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.24636840820312, %, index: 151

INFO 2022-06-06 15:42:45,970 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.077691078186035, %, index: 237

INFO 2022-06-06 15:42:45,971 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573545932769775, %, index: 171

INFO 2022-06-06 15:42:45,972 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0198899507522583, %, index: 158

INFO 2022-06-06 15:42:45,973 [inference.py:<module>:29]
Time for inference:  0.041872 s

INFO 2022-06-06 15:43:46,720 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.24636840820312, %, index: 151

INFO 2022-06-06 15:43:46,723 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.077691078186035, %, index: 237

INFO 2022-06-06 15:43:46,724 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573545932769775, %, index: 171

INFO 2022-06-06 15:43:46,725 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0198899507522583, %, index: 158

INFO 2022-06-06 15:43:46,727 [inference.py:<module>:29]
Time for inference:  0.048118 s

INFO 2022-06-06 15:45:15,649 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.24636840820312, %, index: 151

INFO 2022-06-06 15:45:15,652 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.077691078186035, %, index: 237

INFO 2022-06-06 15:45:15,654 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573545932769775, %, index: 171

INFO 2022-06-06 15:45:15,655 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0198899507522583, %, index: 158

INFO 2022-06-06 15:45:15,656 [inference.py:<module>:29]
Time for inference:  0.046484 s

INFO 2022-06-06 15:54:13,267 [test.py:test_speed:19]

                    Batch size: 2 
                    Time inferene with 100 loop is 1.2635 s
                    >>>> About: 0.012635 s per 1 loop
                

INFO 2022-06-06 15:54:42,379 [test.py:test_speed:19]

        Batch size: 2 
        Time inferene with 100 loop is 1.2546 s
        >>>> About: 0.012546 s per 1 loop
    

INFO 2022-06-06 15:54:52,569 [test.py:test_speed:19]

    Batch size: 2 
    Time inferene with 100 loop is 1.2807 s
    >>>> About: 0.012807 s per 1 loop
    

INFO 2022-06-06 15:58:59,563 [test.py:test_speed:20]

    Batch size: 4 
    Time inferene with 100 loop is 2.1387 s
    >>>> About: 0.021387 s per 1 loop
    

INFO 2022-06-06 15:59:22,482 [test.py:test_speed:20]

    Batch size: 8 
    Time inferene with 20 loop is 0.7326 s
    >>>> About: 0.036629 s per 1 loop
    

INFO 2022-06-06 16:06:53,642 [utils.py:postprocess:37]
class: cup , confidence: 58.57439041137695, %, index: 968

INFO 2022-06-06 16:06:53,645 [utils.py:postprocess:37]
class: espresso , confidence: 38.98651885986328, %, index: 967

INFO 2022-06-06 16:06:53,646 [utils.py:postprocess:37]
class: coffee mug , confidence: 2.20611572265625, %, index: 504

INFO 2022-06-06 16:06:53,647 [inference.py:<module>:29]
Time for inference:  0.043351 s

INFO 2022-06-06 16:08:09,310 [test.py:test_speed:20]

    Batch size: 4 
    Time inferene with 100 loop is 2.1143 s
    >>>> About: 0.021143 s per 1 loop
    

INFO 2022-06-06 16:34:33,055 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.24636840820312, %, index: 151

INFO 2022-06-06 16:34:33,060 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.077691078186035, %, index: 237

INFO 2022-06-06 16:34:33,061 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573545932769775, %, index: 171

INFO 2022-06-06 16:34:33,063 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0198899507522583, %, index: 158

INFO 2022-06-06 16:34:33,064 [inference.py:<module>:29]
Time for inference:  0.145030 s

INFO 2022-06-06 16:59:05,204 [2565630689.py:convert:19]
===> build onnx ...

INFO 2022-06-06 16:59:07,190 [2565630689.py:convert:30]
✅ Convert model pytorch to onnx complete

INFO 2022-06-06 17:00:09,923 [2565630689.py:convert:19]
===> build onnx ...

INFO 2022-06-06 17:00:11,783 [2565630689.py:convert:30]
✅ Convert model pytorch to onnx complete

INFO 2022-06-06 17:01:17,110 [1200333086.py:load:37]
Load onnx done with {self.device}

INFO 2022-06-06 17:01:31,570 [2111965102.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:02:53,201 [2111965102.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:05:17,805 [2111965102.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:05:37,862 [3254488601.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:05:55,915 [4181733994.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:05:56,504 [4181733994.py:postprocess_onnx:75]
class: Chihuahua , confidence: 0.8124645352363586, %, index: 151

INFO 2022-06-06 17:05:56,506 [4181733994.py:inference:49]
Time for inference:  0.543981 s

INFO 2022-06-06 17:06:19,349 [21089939.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:06:19,974 [21089939.py:postprocess_onnx:75]
class: Chihuahua , confidence: 81.24644470214844, %, index: 151

INFO 2022-06-06 17:06:19,976 [21089939.py:postprocess_onnx:75]
class: miniature pinscher , confidence: 15.077646255493164, %, index: 237

INFO 2022-06-06 17:06:19,978 [21089939.py:postprocess_onnx:75]
class: Italian greyhound , confidence: 1.657345175743103, %, index: 171

INFO 2022-06-06 17:06:19,980 [21089939.py:postprocess_onnx:75]
class: toy terrier , confidence: 1.0198869705200195, %, index: 158

INFO 2022-06-06 17:06:19,982 [21089939.py:inference:49]
Time for inference:  0.551140 s

INFO 2022-06-06 17:07:05,492 [3727547070.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:07:06,109 [3727547070.py:postprocess_onnx:75]
class: Chihuahua , confidence:  81.2464, %, index: 151

INFO 2022-06-06 17:07:06,113 [3727547070.py:postprocess_onnx:75]
class: miniature pinscher , confidence:  15.0776, %, index: 237

INFO 2022-06-06 17:07:06,116 [3727547070.py:postprocess_onnx:75]
class: Italian greyhound , confidence:  1.6573, %, index: 171

INFO 2022-06-06 17:07:06,119 [3727547070.py:postprocess_onnx:75]
class: toy terrier , confidence:  1.0199, %, index: 158

INFO 2022-06-06 17:07:06,123 [3727547070.py:inference:49]
Time for inference:  0.584333 s

INFO 2022-06-06 17:14:55,385 [__init__.py:convert:19]
===> build onnx ...

INFO 2022-06-06 17:14:57,092 [__init__.py:convert:30]
✅ Convert model pytorch to onnx complete

INFO 2022-06-06 17:20:02,502 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:20:39,869 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:22:24,344 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:22:24,839 [__init__.py:postprocess_onnx:76]
class: Chihuahua , confidence:  81.2464 %, index: 151

INFO 2022-06-06 17:22:24,844 [__init__.py:postprocess_onnx:76]
class: miniature pinscher , confidence:  15.0776 %, index: 237

INFO 2022-06-06 17:22:24,845 [__init__.py:postprocess_onnx:76]
class: Italian greyhound , confidence:  1.6573 %, index: 171

INFO 2022-06-06 17:22:24,846 [__init__.py:postprocess_onnx:76]
class: toy terrier , confidence:  1.0199 %, index: 158

INFO 2022-06-06 17:22:24,847 [__init__.py:inference:49]
Time for inference:  0.497503 s

INFO 2022-06-06 17:22:57,886 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.24636840820312 %, index: 151

INFO 2022-06-06 17:22:57,889 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.077691078186035 %, index: 237

INFO 2022-06-06 17:22:57,890 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573545932769775 %, index: 171

INFO 2022-06-06 17:22:57,891 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0198899507522583 %, index: 158

INFO 2022-06-06 17:22:57,892 [inference.py:<module>:28]
Time for inference:  0.055912 s

INFO 2022-06-06 17:24:56,553 [3000866572.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:25:00,251 [3000866572.py:postprocess_onnx:75]
class: Chihuahua , confidence:  81.2465 %, index: 151

INFO 2022-06-06 17:25:00,253 [3000866572.py:postprocess_onnx:75]
class: miniature pinscher , confidence:  15.0776 %, index: 237

INFO 2022-06-06 17:25:00,307 [3000866572.py:postprocess_onnx:75]
class: Italian greyhound , confidence:  1.6573 %, index: 171

INFO 2022-06-06 17:25:00,309 [3000866572.py:postprocess_onnx:75]
class: toy terrier , confidence:  1.0199 %, index: 158

INFO 2022-06-06 17:25:00,311 [3000866572.py:inference:49]
Time for inference:  0.605105 s

INFO 2022-06-06 17:25:04,774 [3000866572.py:postprocess_onnx:75]
class: Chihuahua , confidence:  81.2465 %, index: 151

INFO 2022-06-06 17:25:04,777 [3000866572.py:postprocess_onnx:75]
class: miniature pinscher , confidence:  15.0776 %, index: 237

INFO 2022-06-06 17:25:04,779 [3000866572.py:postprocess_onnx:75]
class: Italian greyhound , confidence:  1.6573 %, index: 171

INFO 2022-06-06 17:25:04,782 [3000866572.py:postprocess_onnx:75]
class: toy terrier , confidence:  1.0199 %, index: 158

INFO 2022-06-06 17:25:04,785 [3000866572.py:inference:49]
Time for inference:  0.027165 s

INFO 2022-06-06 17:25:08,203 [3000866572.py:postprocess_onnx:75]
class: Chihuahua , confidence:  81.2465 %, index: 151

INFO 2022-06-06 17:25:08,205 [3000866572.py:postprocess_onnx:75]
class: miniature pinscher , confidence:  15.0776 %, index: 237

INFO 2022-06-06 17:25:08,209 [3000866572.py:postprocess_onnx:75]
class: Italian greyhound , confidence:  1.6573 %, index: 171

INFO 2022-06-06 17:25:08,211 [3000866572.py:postprocess_onnx:75]
class: toy terrier , confidence:  1.0199 %, index: 158

INFO 2022-06-06 17:25:08,213 [3000866572.py:inference:49]
Time for inference:  0.023844 s

INFO 2022-06-06 17:25:12,577 [3000866572.py:postprocess_onnx:75]
class: Chihuahua , confidence:  81.2465 %, index: 151

INFO 2022-06-06 17:25:12,579 [3000866572.py:postprocess_onnx:75]
class: miniature pinscher , confidence:  15.0776 %, index: 237

INFO 2022-06-06 17:25:12,582 [3000866572.py:postprocess_onnx:75]
class: Italian greyhound , confidence:  1.6573 %, index: 171

INFO 2022-06-06 17:25:12,585 [3000866572.py:postprocess_onnx:75]
class: toy terrier , confidence:  1.0199 %, index: 158

INFO 2022-06-06 17:25:12,588 [3000866572.py:inference:49]
Time for inference:  0.024749 s

INFO 2022-06-06 17:29:03,385 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:29:32,085 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 17:29:34,435 [test.py:test_speed:19]

    Batch size: 4 
    Time inferene with 100 loop is 2.3431 s
    >>>> About: 0.023431 s per 1 loop
    

INFO 2022-06-06 21:16:21,165 [convert.py:<module>:15]
Build tensorrt engine...

INFO 2022-06-06 21:16:22,684 [__init__.py:build_engine:71]
✅ Completed parsing ONNX file

INFO 2022-06-06 21:16:22,685 [__init__.py:build_engine:77]
===> using dynamic shapes: {'input': ((1, 3, 224, 224), (32, 3, 224, 224), (32, 3, 224, 224))}

INFO 2022-06-06 21:16:22,686 [__init__.py:build_engine:95]
✅ Creating Tensorrt Engine...

INFO 2022-06-06 21:19:44,369 [convert.py:<module>:15]
Build tensorrt engine...

INFO 2022-06-06 21:19:45,634 [__init__.py:build_engine:71]
✅ Completed parsing ONNX file

INFO 2022-06-06 21:19:45,635 [__init__.py:build_engine:77]
===> using dynamic shapes: {'input': ((1, 3, 224, 224), (2, 3, 224, 224), (2, 3, 224, 224))}

INFO 2022-06-06 21:19:45,641 [__init__.py:build_engine:95]
Creating Tensorrt Engine...

INFO 2022-06-06 21:24:53,191 [convert.py:<module>:14]
Build tensorrt engine...

INFO 2022-06-06 21:24:54,457 [__init__.py:build_engine:71]
✅ Completed parsing ONNX file

INFO 2022-06-06 21:24:54,458 [__init__.py:build_engine:77]
===> using dynamic shapes: {'input': ((1, 3, 224, 224), (1, 3, 224, 224), (1, 3, 224, 224))}

INFO 2022-06-06 21:24:54,464 [__init__.py:build_engine:95]
Creating Tensorrt Engine...

INFO 2022-06-06 21:26:23,062 [convert.py:<module>:14]
Build tensorrt engine...

INFO 2022-06-06 21:26:24,369 [__init__.py:build_engine:71]
✅ Completed parsing ONNX file

INFO 2022-06-06 21:26:24,370 [__init__.py:build_engine:77]
===> using dynamic shapes: {'input': ((1, 3, 224, 224), (32, 3, 224, 224), (32, 3, 224, 224))}

INFO 2022-06-06 21:26:24,376 [__init__.py:build_engine:95]
Creating Tensorrt Engine...

INFO 2022-06-06 21:28:52,570 [__init__.py:build_engine:100]
===> Serialized Engine Saved at: /home/tari/Desktop/STUDY/Optimization/model/model.trt

INFO 2022-06-06 21:44:20,294 [test.py:<module>:14]
✅ Load tensorrt engine done

INFO 2022-06-06 21:55:16,113 [test.py:<module>:19]
✅ Load tensorrt engine done

INFO 2022-06-06 21:55:16,985 [test.py:<module>:26]

    Batch size: 4 
    Time inferene with 100 loop is 0.8646 s
    >>>> About: 0.008646 s per 1 loop
    

INFO 2022-06-06 21:55:31,611 [test.py:<module>:19]
✅ Load tensorrt engine done

INFO 2022-06-06 21:55:33,252 [test.py:<module>:26]

    Batch size: 8 
    Time inferene with 100 loop is 1.6288 s
    >>>> About: 0.016288 s per 1 loop
    

INFO 2022-06-06 21:55:47,943 [test.py:<module>:19]
✅ Load tensorrt engine done

INFO 2022-06-06 21:55:53,621 [test.py:<module>:26]

    Batch size: 32 
    Time inferene with 100 loop is 5.6419 s
    >>>> About: 0.056419 s per 1 loop
    

INFO 2022-06-06 22:00:56,918 [inference.py:<module>:17]
✅ Load tensorrt engine done

INFO 2022-06-06 22:01:14,705 [inference.py:<module>:17]
✅ Load tensorrt engine done

INFO 2022-06-06 22:02:01,623 [inference.py:<module>:17]
✅ Load tensorrt engine done

INFO 2022-06-06 22:02:01,639 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.5375 %, index: 151

INFO 2022-06-06 22:02:01,641 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 14.7993 %, index: 237

INFO 2022-06-06 22:02:01,642 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6645 %, index: 171

INFO 2022-06-06 22:02:01,643 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0030 %, index: 158

INFO 2022-06-06 22:02:01,644 [inference.py:<module>:24]
Time for inference:  0.014279 s

INFO 2022-06-06 22:58:46,095 [inference.py:<module>:19]
>>>>> Pretrain model <<<<<

INFO 2022-06-06 22:58:49,384 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-06 22:58:49,385 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0777 %, index: 237

INFO 2022-06-06 22:58:49,387 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6574 %, index: 171

INFO 2022-06-06 22:58:49,388 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-06 22:58:49,389 [inference.py:<module>:30]
Time for inference:  0.083843 s

INFO 2022-06-06 22:59:45,343 [inference.py:<module>:17]
>>>>> ONNX model <<<<<

INFO 2022-06-06 22:59:48,866 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 22:59:49,612 [__init__.py:postprocess_onnx:76]
class: Chihuahua , confidence:  81.2465 %, index: 151

INFO 2022-06-06 22:59:49,613 [__init__.py:postprocess_onnx:76]
class: miniature pinscher , confidence:  15.0776 %, index: 237

INFO 2022-06-06 22:59:49,614 [__init__.py:postprocess_onnx:76]
class: Italian greyhound , confidence:  1.6573 %, index: 171

INFO 2022-06-06 22:59:49,615 [__init__.py:postprocess_onnx:76]
class: toy terrier , confidence:  1.0199 %, index: 158

INFO 2022-06-06 22:59:49,615 [__init__.py:inference:49]
Time for inference:  0.744216 s

INFO 2022-06-06 23:00:01,347 [inference.py:<module>:17]
>>>>> TensorRt engine <<<<<

INFO 2022-06-06 23:00:01,350 [inference.py:<module>:18]
✅ Load tensorrt engine done

INFO 2022-06-06 23:00:01,363 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.5375 %, index: 151

INFO 2022-06-06 23:00:01,365 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 14.7993 %, index: 237

INFO 2022-06-06 23:00:01,366 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6645 %, index: 171

INFO 2022-06-06 23:00:01,367 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0030 %, index: 158

INFO 2022-06-06 23:00:01,368 [inference.py:<module>:24]
Time for inference:  0.013342 s

INFO 2022-06-06 23:02:20,171 [inference.py:<module>:19]
>>>>> Pretrain model <<<<<

INFO 2022-06-06 23:02:22,502 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-06 23:02:22,503 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0777 %, index: 237

INFO 2022-06-06 23:02:22,504 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6574 %, index: 171

INFO 2022-06-06 23:02:22,505 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-06 23:02:22,506 [inference.py:<module>:30]
Time for inference:  0.045924 s

INFO 2022-06-06 23:02:30,975 [inference.py:<module>:17]
>>>>> ONNX model <<<<<

INFO 2022-06-06 23:02:34,063 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-06 23:02:34,571 [__init__.py:postprocess_onnx:78]
class: Chihuahua , confidence:  81.2464 %, index: 151

INFO 2022-06-06 23:02:34,572 [__init__.py:postprocess_onnx:78]
class: miniature pinscher , confidence:  15.0777 %, index: 237

INFO 2022-06-06 23:02:34,573 [__init__.py:postprocess_onnx:78]
class: Italian greyhound , confidence:  1.6573 %, index: 171

INFO 2022-06-06 23:02:34,574 [__init__.py:postprocess_onnx:78]
class: toy terrier , confidence:  1.0199 %, index: 158

INFO 2022-06-06 23:02:34,575 [__init__.py:inference:51]
Time for inference:  0.018605 s

INFO 2022-06-06 23:02:41,727 [inference.py:<module>:17]
>>>>> TensorRt engine <<<<<

INFO 2022-06-06 23:02:41,731 [inference.py:<module>:18]
✅ Load tensorrt engine done

INFO 2022-06-06 23:02:41,744 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.5375 %, index: 151

INFO 2022-06-06 23:02:41,746 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 14.7993 %, index: 237

INFO 2022-06-06 23:02:41,747 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6645 %, index: 171

INFO 2022-06-06 23:02:41,748 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0030 %, index: 158

INFO 2022-06-06 23:02:41,749 [inference.py:<module>:24]
Time for inference:  0.013857 s

INFO 2022-06-07 14:48:04,250 [test.py:<module>:18]
✅ Load tensorrt engine done

INFO 2022-06-07 14:48:10,014 [test.py:<module>:25]

    Batch size: 32 
    Time inferene with 100 loop is 5.6301 s
    >>>> About: 0.056301 s per 1 loop
    

INFO 2022-06-07 15:47:25,297 [inference.py:<module>:19]
>>>>> Pretrain model <<<<<

INFO 2022-06-07 15:47:28,919 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 15:47:28,921 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0777 %, index: 237

INFO 2022-06-07 15:47:28,922 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6574 %, index: 171

INFO 2022-06-07 15:47:28,923 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 15:47:28,924 [inference.py:<module>:30]
Time for inference:  0.111649 s

INFO 2022-06-07 15:47:43,454 [test.py:test_speed:20]

    Batch size: 4 
    Time inferene with 100 loop is 2.1242 s
    >>>> About: 0.021242 s per 1 loop
    

INFO 2022-06-07 15:48:02,058 [test.py:test_speed:20]

    Batch size: 4 
    Time inferene with 100 loop is 2.1162 s
    >>>> About: 0.021162 s per 1 loop
    

INFO 2022-06-07 15:50:09,128 [__init__.py:convert:19]
===> build onnx ...

INFO 2022-06-07 15:50:10,734 [__init__.py:convert:30]
✅ Convert model pytorch to onnx complete

INFO 2022-06-07 15:51:46,130 [inference.py:<module>:17]
>>>>> ONNX model <<<<<

INFO 2022-06-07 15:51:49,984 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-07 15:51:50,779 [__init__.py:postprocess_onnx:78]
class: Chihuahua , confidence:  81.2464 %, index: 151

INFO 2022-06-07 15:51:50,781 [__init__.py:postprocess_onnx:78]
class: miniature pinscher , confidence:  15.0776 %, index: 237

INFO 2022-06-07 15:51:50,782 [__init__.py:postprocess_onnx:78]
class: Italian greyhound , confidence:  1.6573 %, index: 171

INFO 2022-06-07 15:51:50,783 [__init__.py:postprocess_onnx:78]
class: toy terrier , confidence:  1.0199 %, index: 158

INFO 2022-06-07 15:51:50,783 [__init__.py:inference:51]
Time for inference:  0.019741 s

INFO 2022-06-07 15:52:18,974 [__init__.py:load:37]
Load onnx done with cuda

INFO 2022-06-07 15:52:21,307 [test.py:test_speed:19]

    Batch size: 4 
    Time inferene with 100 loop is 2.3260 s
    >>>> About: 0.023260 s per 1 loop
    

INFO 2022-06-07 15:52:35,815 [convert.py:<module>:14]
Build tensorrt engine...

INFO 2022-06-07 15:52:37,347 [__init__.py:build_engine:71]
✅ Completed parsing ONNX file

INFO 2022-06-07 15:52:37,348 [__init__.py:build_engine:77]
===> using dynamic shapes: {'input': ((1, 3, 224, 224), (32, 3, 224, 224), (32, 3, 224, 224))}

INFO 2022-06-07 15:52:37,350 [__init__.py:build_engine:95]
Creating Tensorrt Engine...

INFO 2022-06-07 15:55:06,457 [__init__.py:build_engine:100]
===> Serialized Engine Saved at: /home/tari/Desktop/STUDY/Optimization/model_repository/model_trt/1/model.trt

INFO 2022-06-07 15:55:33,976 [inference.py:<module>:17]
>>>>> TensorRt engine <<<<<

INFO 2022-06-07 15:55:33,979 [inference.py:<module>:18]
✅ Load tensorrt engine done

INFO 2022-06-07 15:55:33,994 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.5375 %, index: 151

INFO 2022-06-07 15:55:33,995 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 14.7993 %, index: 237

INFO 2022-06-07 15:55:33,996 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6645 %, index: 171

INFO 2022-06-07 15:55:33,997 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0030 %, index: 158

INFO 2022-06-07 15:55:33,999 [inference.py:<module>:24]
Time for inference:  0.015842 s

INFO 2022-06-07 15:55:49,283 [test.py:<module>:18]
✅ Load tensorrt engine done

INFO 2022-06-07 15:55:54,983 [test.py:<module>:25]

    Batch size: 32 
    Time inferene with 100 loop is 5.6553 s
    >>>> About: 0.056553 s per 1 loop
    

INFO 2022-06-07 16:35:18,753 [test.py:<module>:18]


INFO 2022-06-07 16:35:18,765 [test.py:<module>:25]
✅ Load triton client done

INFO 2022-06-07 16:35:20,921 [test.py:<module>:30]

    Batch size: 4 
    Time inferene with 100 loop is 2.1548 s
    >>>> About: 0.021548 s per 1 loop
    

INFO 2022-06-07 16:38:55,660 [test.py:<module>:25]
✅ Load triton client done

INFO 2022-06-07 16:38:57,585 [test.py:<module>:30]

    Batch size: 4 
    Time inferene with 100 loop is 1.9204 s
    >>>> About: 0.019204 s per 1 loop
    

INFO 2022-06-07 16:39:05,760 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:39:13,614 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:39:13,618 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:39:13,780 [inference.py:<module>:28]
Time for inference:  0.157799 s

INFO 2022-06-07 16:39:36,962 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:39:36,964 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:39:36,996 [inference.py:<module>:29]
Time for inference:  0.027035 s

INFO 2022-06-07 16:40:12,795 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:40:12,798 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:40:12,832 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:40:12,833 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:40:12,835 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:40:12,836 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:40:12,837 [inference.py:<module>:30]
Time for inference:  0.034474 s

INFO 2022-06-07 16:40:35,017 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:40:35,020 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:40:35,048 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:40:35,050 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:40:35,051 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:40:35,052 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:40:35,054 [inference.py:<module>:30]
Time for inference:  0.029452 s

INFO 2022-06-07 16:41:28,055 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:41:28,057 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:41:28,100 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:41:28,102 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:41:28,103 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:41:28,104 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:41:28,104 [inference.py:<module>:33]
Time for inference:  0.015692 s

INFO 2022-06-07 16:41:42,244 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:41:42,247 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:41:42,275 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:41:42,277 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:41:42,278 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:41:42,280 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:41:42,281 [inference.py:<module>:32]
Time for inference:  0.017038 s

INFO 2022-06-07 16:42:26,989 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:42:26,992 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:42:27,035 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:42:27,037 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:42:27,039 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:42:27,041 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:42:27,042 [inference.py:<module>:32]
Time for inference:  0.019913 s

INFO 2022-06-07 16:44:42,535 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:44:42,537 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:44:42,579 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:44:42,580 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:44:42,581 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:44:42,582 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:44:55,323 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:44:55,326 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:44:55,356 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:44:55,358 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:44:55,359 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:44:55,360 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:44:55,362 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:44:55,364 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:44:55,365 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:44:55,367 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:44:55,368 [inference.py:<module>:33]
Time for inference:  0.022664 s

INFO 2022-06-07 16:45:02,932 [inference.py:<module>:17]
>>>>> Triton server <<<<<

INFO 2022-06-07 16:45:02,935 [inference.py:<module>:22]
✅ Load triton client done

INFO 2022-06-07 16:45:02,962 [utils.py:postprocess:37]
class: Chihuahua , confidence: 81.2464 %, index: 151

INFO 2022-06-07 16:45:02,964 [utils.py:postprocess:37]
class: miniature pinscher , confidence: 15.0776 %, index: 237

INFO 2022-06-07 16:45:02,965 [utils.py:postprocess:37]
class: Italian greyhound , confidence: 1.6573 %, index: 171

INFO 2022-06-07 16:45:02,966 [utils.py:postprocess:37]
class: toy terrier , confidence: 1.0199 %, index: 158

INFO 2022-06-07 16:45:02,967 [inference.py:<module>:32]
Time for inference:  0.016931 s

